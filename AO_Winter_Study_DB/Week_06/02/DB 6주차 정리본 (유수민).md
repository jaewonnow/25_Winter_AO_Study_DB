# 6주차 — Cache와 DB의 관계

**핵심 질문**

- DB를 안 쓰고도 서비스가 돌아가는 이유는?

**내용**

- Cache 위치별 분류
    - Local Cache
    - Redis
- Write-through / Write-back
- Cache Invalidation 지옥

**키워드**

`Redis`, `TTL`, `Consistency`

---

![스크린샷 2026-01-29 13.59.48.png](6%EC%A3%BC%EC%B0%A8%20%E2%80%94%20Cache%EC%99%80%20DB%EC%9D%98%20%EA%B4%80%EA%B3%84/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2026-01-29_13.59.48.png)

클라이언트, 서버, 데이터베이스 ⇒ 3 Tier 아키텍처 구조

→ 작은 서비스에서는 상관없지만 만약 서비스가 커지게 된다면?

→클라이언트도 많아지고 → 요청도 많아짐 → DB에 대한 부하도 함께 증가

이때 서버와 데이터베이스 사이에 캐시를 도입한다면 성능적인 문제를 해결가능함.

## 캐시란?

데이터나 값을 미리 복사해놓는 임시저장소

## 캐싱이란?

캐시에 접근해서 데이터를 빠르게 가져오는 방식

## 캐시를 사용하는 이유

- 자주 사용되는 데이터를 미리 캐싱해둔다면 효과적인 성능 향상 가능
- 데이터 지역성
    - 공간적 지역성
        - 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성
        - 배열에 있는 하나의 원소에 대해 참조를 하게 됐을 때 주변에 있는 다른 원소들에 대해서도 참조할 확률이 높다는 것
    - 시간적 지역성
        - 사용되었던 데이터가 빠른 시일 내에 다시 사용될 가능성이 높다는 것
        - ex) for문의 i, j

## 캐시 hit와 캐시 miss 란?

- 애플리케이션이 원하는 데이터를 얻기 위해서 먼저 캐시를 조회함
    - 캐시에 데이터가 있다면 바로 받아올 수 있음
        - → cache hit (해당 데이터를 바로 반환)
    - 캐시를 조회했는데 원하는 데이터가 없을 때
        - 데이터베이스로 직접 찾아가서 조회 해야함
        - → cache miss (DB로 가서 데이터를 찾아와 반환)

## 캐시 전략 패턴에 대해

→ 캐시 전략 패턴이란 실제 캐시를 도입할 때 상황에 맞춰 적용될 수 있는 전략 패턴

- 읽기 전략
    - look aside
        
        ![스크린샷 2026-01-29 14.15.41.png](6%EC%A3%BC%EC%B0%A8%20%E2%80%94%20Cache%EC%99%80%20DB%EC%9D%98%20%EA%B4%80%EA%B3%84/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2026-01-29_14.15.41.png)
        
        - = 옆을 보다 = 캐시의 데이터가 없을 때 옆 또는 곁을 보기
        - = 데이터베이스를 조회해서 데이터를 읽어오는 전략
        - 읽어온 데이터는 캐시에 올려놓고 사용
        - 장점: 캐시에 문제가 생기는 경우 DB로 요청을 위임
        - 단점: 캐시, DB의 데이터 정합성 유지 어려움, 첫 조회 시 DB 과부화 발생
    - read through
        
        ![스크린샷 2026-01-29 14.20.25.png](6%EC%A3%BC%EC%B0%A8%20%E2%80%94%20Cache%EC%99%80%20DB%EC%9D%98%20%EA%B4%80%EA%B3%84/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2026-01-29_14.20.25.png)
        
        - = ~을 통하여 읽다 = 항상 캐시를 통해서 읽는 전략
        - 캐시로부터 데이터를 읽어오고
        - 데이터가 캐시에 없다면 캐시가 직접 DB로부터 데이터를 가져온 다음에 올려놓고 사용
        - 장점: 캐시, DB간의 데이터 정합성 보장
        - 단점: 캐시가 죽으면 어플리케이션에 문제 발생
- 쓰기 전략
    - write around
        
        ![스크린샷 2026-01-29 14.23.03.png](6%EC%A3%BC%EC%B0%A8%20%E2%80%94%20Cache%EC%99%80%20DB%EC%9D%98%20%EA%B4%80%EA%B3%84/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2026-01-29_14.23.03.png)
        
        - = 쓰기를 우회한다 = 캐시를 우회하여 직접 DB에 바로 쓰기
        - 장점: 성능이 좋음, 빠름, 리소스 아낄 수 있음
        - 단점: 캐시, DB의 데이터 정합성 유지 어려움
        - but 읽기 전략과 혼합해서 사용할 때는 캐시 미스가 발생한다면 데이터를 캐시 스토어에서 쓰기도 함
    - write back
        
        ![스크린샷 2026-01-29 14.30.33.png](6%EC%A3%BC%EC%B0%A8%20%E2%80%94%20Cache%EC%99%80%20DB%EC%9D%98%20%EA%B4%80%EA%B3%84/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2026-01-29_14.30.33.png)
        
        - = 나중에 쓰다 = 캐시에 데이터를 미리 한꺼번에 써 놓고 나중에 DB에 쓰기 작업을 진행
        - 캐시에 많은 양의 데이터를 써두고 나중에 DB에 쓰기 작업 진행 ← scheduling 방식 사용
        - 일정시간이 지난 뒤에 한꺼번에 많은 양의 데이터를 한번의 쓰기 요청으로 해결 가능
        - 장점: 쓰기 횟수 비용을 줄일 수 있음 (insert문이 하나이므로 성능적 이점)
        - 단점: 캐시의 데이터 유실 문제
    - write through
        
        ![스크린샷 2026-01-29 14.30.03.png](6%EC%A3%BC%EC%B0%A8%20%E2%80%94%20Cache%EC%99%80%20DB%EC%9D%98%20%EA%B4%80%EA%B3%84/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2026-01-29_14.30.03.png)
        
        - = ~을 통하여 쓰다 = 항상 캐시를 통해서 쓰기를 진행
        - 캐시에 먼저쓰고 DB에 바로 쓰기 작업 진행
        - 장점: 데이터 정합성이 보장됨
        - 단점: 두 번의 쓰기가 항상 진행되기 때문에 성능 문제를 고려해야 함

## 캐시 사용 시 주의사항

- 자주 사용되면서 변경이 되지 않는 데이터
- 유실되어도 크게 문제가 없는 데이터
- 데이터베이스와 함께 사용할 때 데이터 정합성 문제 고려

---

## 로컬 캐시(local cache)와 리모트 캐시(remote cache)

→ 기준: 캐시 데이터가 어디에 저장되는가?

→ 구제적으론 애플리케이션 프로세스(서버) 내부에 저장되면 → 로컬

→ 네트워크 너머의 별도 서버에 저장되면 → 리모트 (혹은 글로벌)

- 로컬 캐시 (local cache)
    
    → 데이터를 자신의 서비스가 돌아가는 서버의 메모리나 디스크에 직접 저장함
    
    - 저장 위치: 애플리케이션 서버 내부 (in-process)
    - 특징
        - 속도가 가장 빠름 (바로 메모리에서 꺼내오기 때문)
        - 공유 불가 (서버 간 동기화 문제 발생 가능)
        - 휘발성 (서버 재시작 시 캐시 데이터 휘발)
    - 이용: ehcache, java의 HashMap 등
- 리모트 캐시 (remote cache / global cache)
    
    → 캐시를 저장하기 위한 별도의 캐시 전용 서버를 둠
    
    - 저장 위치: 애플리케이션 외부의 별도 서버 (external server)
    - 특징
        - 네트워크 비용 발생 (네트워크를 타야하므로 로컬보다 느림)
        - 데이터 공유 가능 (여러 서버가 하나의 캐시 저장소 이용하므로 정합성 유지 유리)
        - 지속성 (서버가 죽어도 캐시 서버는 살아있으므로 데이터가 유지됨)
    - 이용: redis, memcached 등

---

## redis란?

- remote dictionary server = 외부에 key-value 구조로 저장하는 서버
    - ex) 전화번호부 → 유수민 : 010-7457-1157 ← key : value 구조
- 즉, redis는 메모리에 저장하는 key-value 기반의 NoSQL DBMS임.
    - 캐시 구현 방법 중 하나임 but 임시작업 큐, 실시간 채팅, 메시지 브로커 등 캐시 이외의 다양한 용도로 활용 가능함
- 특징
    - 메모리에 저장되어 빠른 속도로 접근 가능, get/set 명령어의 경우 10만 TPS (1초당 10만번) 이상 가능
    - value에 다양한 자료구조를 제공함(collection) ⇒ 개발의 편의성 증가 (key는 기본적으로 string) (value는 hash, list set, sorted set 등등)
    - single thread로 동작하여 한번에 하나의 명령만을 처리함 → race condition이 거의 발생하지 않음
    - 메모리에 저장된 데이터를 디스크에 영속화함(persistence) → 서버에 치명적인 문제가 발생하더라도 복구 가능
        - RDB (=redis database backup)
            
            ![스크린샷 2026-01-29 18.38.18.png](6%EC%A3%BC%EC%B0%A8%20%E2%80%94%20Cache%EC%99%80%20DB%EC%9D%98%20%EA%B4%80%EA%B3%84/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2026-01-29_18.38.18.png)
            
            - 특정한 간격으로 현재 redis의 메모리에 존재하는 데이터의 스냅샷을 남기는 방식
            - 장점: 압축하여 저장하기 때문에 AOF보다 크기가 작음, 로딩/복구 속도가 빠름
            - 단점: 백업 중 서버가 다운될 경우 최신 데이터 유실 가능성 존재
        - AOF (=append only file)
            
            ![스크린샷 2026-01-29 18.40.08.png](6%EC%A3%BC%EC%B0%A8%20%E2%80%94%20Cache%EC%99%80%20DB%EC%9D%98%20%EA%B4%80%EA%B3%84/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2026-01-29_18.40.08.png)
            
            - 입력/수정/삭제 명령이 실행될 때마다 log 파일에 기록
            - 장점: 저장 속도 빠름, 실시간 데이터 백업 가능, 데이터 손실 거의 없음
            - 단점: 명령 실행 기록을 모두 기록하기 때문에 파일 크기가 큼, 복원 소요시간이 김
- 잘 사용하는 방법
    - 데이터 타입에 따른 적절한 자료구조 사용
        - 최근 검색 목록을 표시하는
    - O(n) 명령어 주의
        - single thread로 동작하기 때문에 O(n)의 명령어는 해당 명령이 처리될 때까지 다음 명령어들이 대기 상태로 전환되는 문제가 발생함
        - 빠른 성능을 위해 사용한 redis의 목적과는 다르게 더 느린 성능이 제공될 수 있음
    - 메모리 관리
        - redis의 경우 인메모리 데이터 스토어이므로 메모리 관리가 필수적임 → 메모리 특성상 메모리 단편화가 발생함
        - 메모리 단편화: 메모리가 작은 공간으로 나뉘어져 관리되어서 사용 가능한 공간이 충분한데도 불구하고 해당 메모리를 할당하지 못하는 상태를 의미
        - RSS (resident set size, 실제 물리 메모리 사용량) 모니터링 필요함
    - redis의 목적성
        - 캐시용으로 사용할지, 저장소용으로 사용할지
        - why? → persistence 기능(RDB, AOF)이 장애 발생 가능성이 높다고 알려짐
        - redis에 저장되었던 데이터가 없어져도 문제가 없는지, 일부 값이 유실되어도 치명적이지 않은지 → persistence 기능 OFF (캐시용)

---

## cache invalidation (캐시 무효화) 지옥이란?

- DB는 바뀌었는데 캐시 데이터가 제때 갱신되지 않아서 사용자가 과거의 잘못된 데이터를 보게 되는 상황
- 이를 해결하기 위해 복잡한 로직을 짜다가 발생하는 각종 버그와 혼란
- 즉, DB랑 캐시랑 내용이 서로 달라서 생기는 대혼란임

invalidation이라고 부르는 이유

→ 캐시를 업데이트하는 것이 아니라 기존 캐시를 invalid로 만들고(삭제) 다시 채우도록 유도하는 것이기 때문임

캐시를 지우거나 업데이트하는 것이 힘든 이유

1. 타이밍의 불일치 (데이터 정합성이 깨짐)
    1. DB는 변경되었지만 캐시는 변경되지 않아 혼란이 오는것
2. 의존성 문제
    1. 무엇을 지워야 할지 모르는 것
    2. 하나를 바꿨는데 연관된 캐시를 다 찾아서 지우는 로직을 짜는 것이 너무 복잡하고 실수하게 되면 버그가 됨
3. 동시성 문제 (race condition)
    
    ![스크린샷 2026-01-29 17.34.48.png](6%EC%A3%BC%EC%B0%A8%20%E2%80%94%20Cache%EC%99%80%20DB%EC%9D%98%20%EA%B4%80%EA%B3%84/d4db14e9-74d3-4be3-9d43-4f9959db4ff7.png)
    
    1. 두 개 이상의 프로세스가 동시적으로 하나의 리소스에 접근하여서 서로 경쟁하는 상태
    2. 하나는 수행되지만 그 다음 프로세스는 캐시에 저장되어 영원히 갱신되지 않는 데이터가 되어 캐시에 남게 됨
4. 로컬 캐시에서는 특히 더 힘듬
    1. 로컬 캐시는 공유가 불가하기 때문에 서버가 5대라고 한다면 A가 캐시를 갱신했을 때 나머지 서버는 변경이 안됨
    2. 즉, 사용자가 새로고침 할 때마다 어떤 서버에 접속하냐에 따라 값이 계속 바뀌어 보이는 혼란 상황이 발생함

## 해결 방법

1. TTL (Time To Live) 설정하기
    1. 만료 시간을 설정하는 방법, 거의 모든 캐시 시스템의 기본 안전장치임
    2. 방식: 시간 설정 → 캐시 저장소가 알아서 데이터 지움 → DB에서 최신 값을 가져와 캐시 채움
    3. 장점: 구현이 쉬움, 알아서 최신 데이터로 맞춰짐
    4. 단점: 만료 시간이 되기 전까진 데이터 적합성이 떨어짐
    5. 사용 적절한 상황: 실시간성이 많이는 필요 없는 데이터 
        1. ex) 인기 검색어 순위, 공지사항, 추천 상품 목록 등
2. look(cache) aside 패턴 (수정 시 삭제)
    1. 데이터를 수정할 때 캐시를 갱신하는 게 아니라 삭제해버리는 것, 정석 패턴
    2. 방식: DB 업데이트 → 해당 키 캐시 삭제 → DB에서 최신 값을 가져와 캐시 채움
    3. 갱신하지 않고 삭제하는 이유: race condition을 막기 위해서임. 두 트랜잭션이 동시에 캐시를 갱신하려고 할 때 DB 트랜잭션의 커밋 순서와 캐시 셋 순서가 어긋나면 영구적인 데이터 불일치가 발생하기 때문임. 삭제는 순서가 꼬여도 다음 읽기 요청 시 DB에서 최신 값을 가져오므로 안전함.
    4. 장점: 데이터 정합성에 유리, lazy loading이므로 캐시 공간을 차지하지 않음
    5. 단점: 삭제 후 첫 번째 요청은 속도가 느림. (cache miss → DB 조회 과정 필요) → Thundering Herd 문제라고도 함
    6. 사용 적절한 상황: 일반적인 웹 서비스 대부분의 데이터
        1. ex) 사용자 프로필, 게시글 수정 등
3. Pub/Sub propagation (메시지 브로커 활용)
    1. 캐시 변경 사실을 다른 서버에 방송하는 것, 로컬 캐시를 사용하는 분산 서버 환경에서 필수적
    2. 방식: 서버 A DB 업데이트 → A 로컬 캐시 삭제 → 메시지 브로커(redis Pub/Sub, Kafka)를 통해 invalidation 메시지 발행 → 메시지를 받은 다른 서버들은 자신들의 로컬 캐시 삭제
    3. 장점: 속도가 빠른 로컬 캐시의 장점 이용 가능, 서버 간 데이터 불일치 문제 해결 가능
    4. 단점: 시스템 복잡도 증가(별도의 메시지 브로커 필요), 메시지가 전달되는 순간에는 데이터 불일치 가능성 존재
    5. 사용 적절한 상황: 자주 안 바뀌지만 조회는 많은 데이터를 로컬 캐시로 사용할 때
        1. ex) 글로벌 설정 정보, 코드성 데이터 등

| **상황** | **추천 전략** | **핵심 기술 요소** | **예시** |
| --- | --- | --- | --- |
| **일반적인 웹/앱 (읽기 위주)** | **look(cache) Aside + TTL** | DB 업데이트 후 캐시 삭제, TTL 필수 설정 | **SNS 피그, 블로그, 이커머스 상품 정보 
(read heavy & 정합성이 중요하지만 약간의 지연 허용)** |
| **쓰기 부하가 매우 높음** | **Write Back** | 배치 프로세싱, 비동기 쓰기 | **데이터 유실 위험을 감수하더라도 대량의 데이터를 빠르게 저장해야 하는 경우 
(write heavy & 쓰기 성능 최우선, logging, analytics)** |
| **데이터 정합성 필수** | **Write Through** | 캐시-DB 강결합, 쓰기 성능 희생 | **데이터가 절대 꼬이면 안되며 캐시와 DB가 항상 동기화되어야 하는 경우 
(데이터 무결성 최우선, financial, inventory)** |
| **로컬 캐시 동기화** | **Pub/Sub** | Redis Pub/Sub, Kafka 등을 통한 이벤트 전파 | **로컬 캐시를 사용하며 여러 서버 간 데이터를 맞춰야 하는 경우 
(분산 환경에서의 로컬 캐시 동기화, microservices)** |